---
layout: post
title: 操作系统总结
date: 2018-4-10
categories: study
tags:
  - 操作系统
---

# 第1章 导论

## 1.1 操作系统做什么

计算机系统分为4个组成部分：计算机硬件、操作系统、系统程序与应用程序、用户。

操作系统是一直运行在计算机上的程序，通常称为**内核**。

## 1.2 计算机系统组织

当打开电源或重启时，计算机会运行一个初始化程序。该初始化程序或**引导程序(bootstrap program)**比较简单，通常位于ROM或EEPROM(电可擦可编程只读存储器)中，称为计算机硬件中的固件。

事件的发生通常通过硬件或软件**中断(interrupt)**来表示，硬件可随时通过系统总线向CPU发出信号触发中断，软件通过执行特别操作如**系统调用(system call)**(也称为**监视器调用(monitor call)**)来触发中断。

中断必须将控制转移到合适的中断处理程序，处理转移的简单方法时调用一个通用子程序以检查中断信息。中断处理子程序的指针表通常位于低地址内存，包含了各种设备的中断处理子程序的地址。这种地址的数组或**中断向量(interrupt vector)**可通过唯一设备号来索引，以提供设备的中断处理子程序的地址。

一个典型指令执行周期(冯诺依曼体系)，首先从内存中获取指令，并保存在**指令寄存器(instruction register)**中。接着指令被解码，并可能从内存中获取操作数或将操作数储存到内部寄存器中。对操作数完成执行后，其结果可以存回内存中。

**辅存(secondary storage)**作为内存的扩充，需要能够永久地存储大量的数据。

* **SCSI(small computer system interface)**控制器：小型计算机系统接口
* **DMA(direct memory access)**：直接内存访问

## 1.3 计算机系统体系结构

* 多处理器系统：也称**并行系统(parallel system)**或**紧耦合系统(tightly coupled system)**
* **适度退化(graceful degradation)**：提供能与正常工作的硬件成正比的服务的能力
* **容错(fault tolerant)**：系统超出适度退化的能力
* **非对称多处理(asymmetric multiprocessing)**：每个处理器都有各自特定的任务，主从关系
* **对称多处理(symmetric multiprocessing, SMP)**：每个处理器都要完成操作系统中的所有任务
* **刀片服务器(blade server)**：每个刀片处理器独立启动并运行各自的操作系统
* **集群系统(clustered system)**：两个或多个独立的系统耦合起来
* **非对称集群(asymmetric clustering)**：一台机器处于**热备份模式(hot standby mode)**，另一台运行应用程序。
* **对称集群(symmetric clustering)**：主机都运行应用程序，互相监督

## 1.4 操作系统结构

**多道程序设计**通过组织作业使CPU总有一个作业可执行，从而提高了CPU的利用率。**分时系统**(或多任务)是多道程序设计的延伸，切换频率很高。

* **进程(process)**：装到内存并执行的程序
* **作业调度(job scheduling)**：作业需要调入内存但没有足够的内存，系统必须在作业中做出选择决策

## 1.5 操作系统操作

操作系统采取提供硬件支持的方法以允许区分各种执行模式。至少需要两种独立的操作模式：**用户模式(user mode)**和**监督程序模式(monitor mode)**(也叫管理模式supervisor mode、系统模式system mode、特权模式privileged mode)。在计算机硬件中添加一个称为**模式位(mode bit)**的位以表示当前模式。

一旦出现陷阱或中断，硬件会从用户模式切换到内核模式(即将模式位设为0)。双重模式操作提供了保护操作系统和用户程序不受错误用户程序影响的手段，其方法为将能引起损害的机器指令作为**特权指令(privileged instruction)**。

必须确保操作系统能维持对CPU的控制，也必须防止用户程序陷入死循环或不调用系统服务，并且不将控制权返回到操作系统。为了实现这一目标，可使用**定时器(timer)**。**可变定时器(variable timer)**一般通过一个固定速率的时钟和计数器来实现。

## 1.6 进程管理

处于执行中的程序被称为进程，可以将进程视为作业或分时程序。程序不是进程，程序是被动的实体，进程是活动的实体。

进程是系统工作的单元。操作系统负责下述与进程管理相关的活动：

* 创建和删除用户进程和系统进程
* 挂起和重启进程
* 提供进程同步机制
* 提供进程通信机制
* 提供死锁处理机制

## 1.7 内存管理

内存是现代计算机系统操作的中心。内存通常是CPU所能直接寻址和访问的唯一大容量存储器，硬盘必须先通过CPU生成的I/O调用传送到内存。

操作系统负责下述有关内存管理的活动：

* 记录内存哪部分正在被使用及被谁使用
* 当有内存空间时，决定哪些进程可以装入内存
* 根据需要分配和释放内存空间

## 1.8 存储管理

操作系统负责下列有关硬盘管理的活动：

* 空闲空间管理
* 存储空间分配
* 硬盘调度

**三级存储(tertiary storage)**：CD/DVD驱动器、光盘。

**高速缓存一致性(cache coherency)**：必须确保在一个高速缓存中对A值的更新马上反映在所有其他A所在的高速缓存中。

I/O子系统包括如下几个部分：

* 一个包括缓冲、高速缓存和假脱机的内存管理部分
* 通用设备驱动器接口
* 特定硬件设备的驱动程序

## 1.9 保护和安全

绝大多数操作系统维护一个用户和相关用户标识(user ID, UID)的链表，在Windows NT中，这称为**安全ID(Secure ID, SID)**。用户有时需要**升级特权(escalate privilege)**来获取对一个活动的额外特权。

## 1.10 分布式系统

分布式系统包括两种模式的组合，FTP和NFS。

* **局域网**：local-area network, LAN
* **广域网**：wide-area network, WAN
* **城域网**：metropolitan-area network, MAN
* **小域网**：small-area network, SAN，由蓝牙(Blue Tooth)和802.11实现

## 1.11 专用系统

* 实时嵌入式系统
* 多媒体系统
* 手持系统

## 1.12 计算环境

* 传统计算
* 客户机-服务器计算
* 对等计算
* 基于Web的计算

# 第2章 操作系统结构

## 2.1 操作系统服务

* 用户界面(user interface, UI)：command-line interface(CLI)、graphical user interface(GUI)
* 程序执行：系统必须能将程序装入内存并运行
* I/O操作
* 文件系统操作
* 通信：进程之间交换信息
* 错误检测
* 资源分配
* 统计
* 保护和安全

## 2.2 操作系统的用户界面

命令解释程序的主要作用是获取并执行用户指定的下一条命令。

## 2.3 系统调用

```c
BOOL WINAPI ReadFile(
  _In_        HANDLE       hFile,
  _Out_       LPVOID       lpBuffer,
  _In_        DWORD        nNumberOfBytesToRead,
  _Out_opt_   LPDWORD      lpNumberOfBytesRead,
  _Inout_opt_ LPOVERLAPPED lpOverlapped
);
```

Win32函数`CreateProcess()`实际上调用了Windows内核中的`NTCreateProcess()`系统调用。

向操作系统传递参数有三种方法：

* 通过寄存器来传递参数
* 参数存在内存的块和表中，并将块的地址通过寄存器来传递(Linux、Solaris)
* 通过程序放在或压入堆栈中，并通过操作系统弹出

## 2.4 系统调用类型

系统调用大致可分成5类：**进程控制**、**文件管理**、**设备管理**、**信息维护**、**通信**。

**控制卡**是一个批处理系统概念，它是一个管理进程执行的命令。如果程序非正常终止，它可能需要定义一个错误级别。

Solaris 10操作系统包含了dtrace动态跟踪工具，可以动态探测运行的系统。

通信有两种模型：**消息传递模型(message-passing model)**、**共享内存模型(shared-memory model)**。

## 2.5 系统程序

* 文件管理
* 状态信息：日期、可用内存等等
* 文件修改
* 程序语言支持
* 程序装入和执行
* 通信

## 2.6 操作系统设计和实现

设计目标：用户目标和系统目标

**策略(policy)**和**机制(mechanism)**是重要原理，机制决定如何做，策略决定做什么。

## 2.7 操作系统结构

内核和系统程序独立组成，内核进一步分成一系列接口和驱动程序。

系统模块化可用**分层法**，即操作系统分成若干层，最底层是硬件，最高层是用户接口。

Mach操作系统采用了**微内核(microkernel)**技术来模块化内核，这种方法将所有非基本部分从内核中移走，并将它们实现为系统程序或用户程序。

## 2.8 虚拟机

虚拟机本身只能运行在用户模式，所以要模拟出虚拟用户模式和虚拟内核模式。

* VMware
* Java JVM
* .NET CLR

## 2.9 系统生成

对于某个特定的计算机场所，必须要配置和生成系统，这一过程有时称为**系统生成(system generation, SYSGEN)**。

## 2.10 系统启动

**引导程序(引导装载程序)**能定位内核，将它装入内存，开始执行。


# 第3章 进程

## 3.1 进程概念

进程包括程序代码(**文本段**)、当前活动(通过**程序计数器**的值和寄存器的内容来表示)、进程**堆栈段**、**数据段**、**堆**。

程序是被动实体，进程是活动实体。

每个进程在操作系统内用**进程控制块(process control block, PCB, 也叫任务控制块)**来表示：

* 进程状态
* 程序计数器
* CPU寄存器
* CPU调度信息：包括进程优先级、调度队列的指针和其他调度参数
* 内存管理信息：基址、界限寄存器的值、页表或段表
* 记账信息：CPU时间、实际使用时间、时间界限、记账数据、作业或进程数量
* I/O状态信息：分配给进程的I/O设备列表、打开的文件列表

## 3.2 进程调度

多道程序设计中，进程调度选择一个可用的进程到CPU上执行。

就绪队列通常用链表来实现，其头节点指向链表的第一个和最后一个PCB块的指针，每个PCB包含一个指向就绪队列的下一个PCB的指针域。

```c
// Linux的进程控制块
struct task_struct {
  pid_t pid; /* process identifier */
  long state; /* state of the process */
  unsigned int time_slice; /* scheduling information */
  struct files_struct* files; /* list of open files */
  struct mm_struct* mm; /* address space of this process */
};
```

等待特定I/O设备的进程列表称为**设备队列**。

进程分配到CPU执行时，发生下面的事件之一：

* 进程可能发出一个I/O请求，并被放到I/O队列中
* 进程可能创建一个新的子进程，并等待其结束
* 进程可能会由于中断而强制释放CPU，并被放回到就绪队列中

进程选择是由相应的**调度程序(scheduler)**来执行的：**长期调度程序(long-term scheduler)**或**作业调度程序(job scheduler)**从缓冲池中选择进程，并装入内存以准备执行。**短期调度程序(short-term scheduler)**或**CPU调度程序**从准备执行的进程中选择进程，并为之分配CPU。两者的主要区别在于它们的执行频率。

有的系统没有长期调度程序，UNIX和Windows的分时系统只是简单地将所有新进程放在内存中以供短期调度程序使用。这些系统地稳定性依赖于物理限制(如可用的终端数)或用户的自我调整。

有的系统如分时系统引入了**中期调度程序(medium-term scheduler)**，其核心思想是能将进程从内存或CPU竞争中移出，从而降低多道程序设计的程度。进程能被重新调入内存，并从中断处继续执行，这种方案叫做交换(swapping)。

**上下文切换(context switch)**：将CPU切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态。

## 3.3 进程操作

进程能通过创建进程系统调用(create-process system call)创建多个新进程，从而形成进程树。大多数操作系统根据一个唯一的进程标识符(process identifier, pid)来识别进程，pid通常是一个整数值。

在Solaris系统里面，树顶端的进程是标识符为0的Sched进程。Sched进程生成几个子进程，包括pageout和fsflush，分别负责内存管理和文件系统。Sched进程还生成init进程，作为所有用户进程的根进程。

命令`ps -el`可以列出系统所有当前活动进程的完整信息。

```c
#include <sys/types.h>
#include <unistd.h>
#include <stdio.h>

int main(void) {
    pid_t pid = fork();
    if (pid < 0) {
        fprintf(stderr, "Fork Failed\n");
        exit(-1);
    } else if (pid == 0) {
        // child process
        execlp("/bin/ls", "ls", NULL);
    } else {
        // parent will wait for the child to complete
        wait(NULL);
        printf("Child Complete");
        exit(0);
    }
}
```

```c
#include <windows.h>
#include <stdio.h>

int main(void) {
    STARTUPINFO si;
    PROCESS_INFORMATION pi;

    // allocate memory
    ZeroMemory(&si, sizeof(si));
    si.cb = sizeof(si);
    ZeroMemory(&pi, sizeof(pi));

    // create child process
    if (!CreateProcess(NULL, 
        "C:\\Windows\\system32\\mspaint.exe",
        NULL,
        NULL,
        FALSE,
        0,
        NULL,
        NULL,
        &si,
        &pi)) {
        fprintf(stderr, "Create Process Failed");
        return -1;
    }
    WaitForSingleObject(pi.hProcess, INFINITE);
    printf("Child Complete");

    // close handles
    CloseHandle(pi.hProcess);
    CloseHandle(pi.hThread);
}
```

进程可以通过适当的系统调用来终止另一个进程，比如Win32的`TerminateProcess()`，但是只有被终止进程的父进程才能执行这以系统调用。

**级联终止(cascading termination)**：父进程已终止的情况下，某些系统不允许子进程再存在，子进程的终止由操作系统进行。

## 3.4 进程间通信

操作系统内并发执行的进程可以是独立进程或协作进程。独立进程不能影响其他进程或被其他进程所影响，协作进程能影响其他进程或被其他进程影响。

**使用进程协作的理由**：

* 信息共享
* 提高运算速度，子任务
* 模块化
* 方便

协作进程需要一种进程间通信机制(inter process communication, IPC)来允许进程相互交换数据与信息。通信基本模式：共享内存、消息传递。

缓冲：**无限缓冲(unbounded-buffer)**、**有限缓冲(bounded-buffer)**。

通信需要**通信线路(communication link)**，该线路有多种实现方法：

* 直接或间接通信
* 同步或异步通信
* 自动或显式缓冲

直接通信：`send(P, message)`、`receive(Q, message)`。

间接通信：`send(A, message)`、`receive(A, message)`。

同步异步通信：`阻塞send`、`非阻塞send`和`阻塞receive`、`非阻塞receive`组合。

缓冲：零容量(阻塞send)、有限容量、无限容量。

## 3.5 IPC系统的实例

**POSIX共享内存**：

进程必须首先用系统调用`shmget()`创建共享内存段，想访问共享内存段的进程必须采用`shmat()`系统调用来将其加入地址空间，然后使用`shmat()`返回的指针来访问共享内存。当进程不再需要访问共享内存段时，将指针传递给系统调用`shmdt()`分离共享内存段。`shmctl()`用于删除共享内存段。

**Mach**：

* `msg_send()`：向邮箱发送消息
* `msg_receive()`：接收消息
* `msg_rpc()`：远程过程调用(RPC)，能发送消息并只等待来自发送者的一个返回信息
* `port_allocate()`：创建新邮箱并为其消息队列分配空间

**Windows XP**：

Windows XP的消息传递工具称为本地过程调用(LPC)工具。端口消息传递最多能发送256B消息，更大的消息需要通过**区段对象**(构建共享内存)来传递消息。

Windows XP的LPC工具并不是Win32 API的一部分，应用程序应该使用Win32 API调用标准用的远程过程调用。

## 3.6 客户机-服务器系统通信

* **Socket**：服务器监听指定端口，客户端发送Socket连接。
* **远程过程调用(RPC)**：RPC语义允许客户机调用位于远程主机上的过程，需要定义数据的机器无关表示
* **远程方法调用(RMI)**：类似RPC的Java特性，远程指JVM不同，基于对象


# 第4章 线程

## 4.1 概述

 线程是CPU使用的基本单元，它由线程ID、程序计数器、寄存器集合和栈组成。它与属于同一进程的其他线程共享代码段、数据段和其他操作系统资源。

多线程编程有下列优点：

* 响应度高，即使有阻塞和执行较冗长的操作，程序仍能继续执行
* 资源共享
* 经济，不用执行创建进程所需要的内存和资源的分配工作
* 多处理器体系结构的利用，加强并发功能

## 4.2 多线程模型

有两种不同方法来提供线程支持：用户层的用户线程、内核层的内核线程。用户线程受内核支持，而无需内核管理；而内核线程由操作系统直接支持和管理。

多对一模型将许多用户级线程映射到一个内核线程。线程管理是由线程库在用户空间进行的，因而效率比较高。但如果一个线程执行了阻塞系统调用，那么整个进程会阻塞。因为任一时刻只有一个线程能访问内核，多个线程不能并行运行在多处理器上。**Green thread**(Solaris所应用的线程库)和**GNU可移植线程**(GNU Portable Threads)就是使用了这种模型。

一对一模型将每个用户线程映射到一个内核线程。缺点是每创建一个用户线程就需要创建一个相应的内核线程。Linux和Windows使用一对一模型。

多对多模型多路复用了许多用户线程到同样数量或更小数量的内核线程上。多对多模型没有两者的缺点：开发人员可以创建任意多的用户线程，并且相应内核线程能在多处理器系统上并发执行。IRIX、HP-UX、Tru64 UNIX等操作系统支持多对多模型，Solaris 9之前支持二级模型，之后开始使用一对一模型。

## 4.3 线程库

**线程库(thread library)**为程序员提供创建和管理线程的API，有两种方法实现线程库：

* 在用户空间中提供一个没有内核支持的库，库的代码和数据结构都存在用户空间中。
* 执行一个由操作系统直接支持的内核级的库，库的代码和数据结构都存在内核空间中。


目前常用的三种线程库：

* POSIX Pthread：作为POSIX标准的扩展，可以提供用户级或内核级的库。
* Win32：适用于Windows的内核级线程库。
* Java：线程API允许线程在Java程序中直接创建和管理，通常采用宿主系统上的线程库来实现。

Pthread是由POSIX标准(IEEE 1003.1c)为线程创建和同步定义的API，这是线程行为的规范，而不是实现。

```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>

int sum;
void* runner(void* param);

int main(int argv, char* args[]) {
    pthread_t tid;
    pthread_attr_t attr;
    if (argv != 2) {
        fprintf(stderr, "usage: ./a.out <integer value>\n");
        return -1;
    }
    if (atoi(args[1]) < 0) {
        fprintf(stderr, "%d must be >= 0\n", atoi(args[1]));
        return -1;
    }
    pthread_attr_init(&attr);
    pthread_create(&tid, &attr, runner, args[1]);
    pthread_join(tid, NULL);
    printf("sum = %d\n", sum);
}

void* runner(void* param) {
    int upper = atoi(param);
    sum = 0;
    for (int i = 1; i <= upper; i++) {
        sum += i;
    }
    pthread_exit(0);
}
```

Windows32线程库创建线程的技术与Pthread很相似。

```c
#include <windows.h>
#include <stdio.h>
#include <stdlib.h>

DWORD sum;
DWORD WINAPI Summation(LPVOID param);

int main(int argv, char* args[]) {
    DWORD threadId;
    HANDLE threadHandle;
    int param;
    if (argv != 2) {
        fprintf(stderr, "usage: ./a.exe <integer value>\n");
        return -1;
    }
    param = atoi(args[1]);
    if (param < 0) {
        fprintf(stderr, "%d must be >= 0\n", atoi(args[1]));
        return -1;
    }
    threadHandle = CreateThread(NULL, 0, Summation, &param, 0, &threadId);
    if (threadHandle != NULL) {
        WaitForSingleObject(threadHandle, INFINITE);
        CloseHandle(threadHandle);
        printf("sum = %d\n", sum);
    }
}

DWORD WINAPI Summation(LPVOID param) {
    DWORD upper = *(DWORD*) param;
    for (DWORD i = 1; i <= upper; i++) {
        sum += i;
    }
    return 0;
}
```

Java程序中有两种创建线程的技术：一种是创建一个新的类，它从`Thread`类派生，并重写其`run()`；另一种方法是定义一个实现`Runnable`接口的类。

```java
public final class JavaThread {
    private JavaThread() {
        // Do nothing
    }

    public static void main(String[] args) {
        if (args.length > 0) {
            int upper = Integer.parseInt(args[0]);
            if (upper < 0) {
                System.err.println(args[0] + " must be >= 0");
            } else {
                Sum sum = new Sum();
                Thread thrd = new Thread(new Summation(upper, sum));
                thrd.start();
                try {
                    thrd.join();
                    System.out.println("sum = " + sum.getSum());
                } catch (InterruptedException ie) {
                    System.err.println(ie.toString());
                }
            }
        } else {
            System.err.println("usage: java JavaThread <integer value>");
        }
    }
}

final class Sum {
    private int sum;

    public int getSum() {
        return sum;
    }

    public void setSum(int value) {
        this.sum = value;
    }
}

final class Summation implements Runnable {
    private int upper;
    private Sum sumValue;

    public Summation(int upper, Sum sumValue) {
        this.upper = upper;
        this.sumValue = sumValue;
    }

    public void run() {
        int sum = 0;
        for (int i = 1; i <= upper; i++) {
            sum += i;
        }
        sumValue.setSum(sum);
    }
}
```

## 4.4 多线程问题

有的UNIX系统有两种形式的`fork()`，一种复制所有的线程，另一种只复制调用了系统调用`fork()`的线程。如果一个线程调用了系统调用`exec()`，那么`exec()`参数所指定的程序会替换整个进程，包括所有线程。

**线程取消(thread cancellation)**是在线程完成之前来终止线程的任务。要取消的线程通常称为**目标线程**，目标线程的取消可在如下两种情况下发生:

1. **异步取消(asynchronous cancellation)**：一个线程立即终止目标线程。
2. **延迟取消(deferred cancellation)**：目标线程不断地检查它是否应终止，这允许目标线程有机会以有序方式来终止自己。

异步取消线程并不会使所需的系统资源空闲，相反采用延迟取消时，需要一个线程检查一个标志以确定它是否应该取消。Pthread称这些点为**取消点(cancellation point)**。

**信号**在UNIX中用来通知进程某个特定事件已发生了，可以同步或异步接收。每个信号都有一个**默认信号处理程序(default signal handler)**，当处理信号时在内核中运行。

单线程程序的信号总是发给进程，多线程程序中，同步信号需要发送到产生这一信号的线程，而异步信号情况就不是那么清楚了。有些异步信号如终止进程信号(Ctrl+C)应该发送给所有线程。

**UNIX信号发送**：

* `kill(pid_t pid, int signal)`：标准的发送信号的UNIX函数
* `pthread_kill(pthread_t tid, int signal)`：POSIX Pthread提供的函数，允许发送到指定线程

Windows不明确提供对信号的支持，但是能通过**异步过程调用(asynchronous procedure call, APC)**来模拟。APC只发送特定线程而不是进程。

**线程池(thread pool)**的主要思想是在进程开始时创建一定数量的线程，并放入到池中以等待工作。当服务器收到请求时，它会唤醒池中的一个线程(如果有可以用的线程)，并将要处理的请求传递给它。

线程池的优点：

* 通常用现有线程处理请求要比等待创建新的线程要快。
* 线程池限制了在任何时候可用线程的数量。

许多实现多对多模型或二级模型的系统在用户和内核线程之间设置一种中间数据结构，通常是**轻量级进程(LWP)**。对于用户线程库，LWP表现为一种应用程序可以调度用户线程来允许的虚拟处理器，每个LWP与内核线程相连。

一种解决用户线程库与内核间通信的方法被称为**调度器激活(scheduler activation)**。内核提供一组虚拟处理器(LWP)给应用程序，应用程序课调度用户线程到一个可用的虚拟处理器上。进一步说，内核必须告知与应用程序有关的特定事件，这个过程被称为`upcall`。

## 4.5 操作系统实例

* Windows XP线程：提供了`fiber`库的支持，该库提供了多对多模型的功能。
* Linux线程：传统进程复制`fork()`、创建线程`clone()`，Linux不区分进程和线程，通常称之为任务。

# 第5章 CPU调度

## 5.1 基本概念

CPU的成功调用依赖于进程的如下属性：进程执行由CPU执行和I/O等待周期组成。

每当CPU空闲时，操作系统就必须从就绪队列中选择一个进程来执行。进程选择由**短期调度程序(short-term scheduler)**或**CPU调度程序**执行。就绪队列不必是先进先出(FIFO)队列。

CPU调度决策在4种环境下发生：

* 当一个进程从运行状态切换到等待状态(如I/O请求)
* 当一个进程从运行状态切换到就绪状态(如中断发生)
* 当一个进程从等待状态切换到就绪状态(如I/O完成)
* 当一个进程终止时

1、4两种情况没有选择只有调度，称调度方案是**非抢占的(non-preemptive)**或**协作的(co-operative)**。2、3两种情况可以选择，称调度方案是**抢占的(preemptive)**。

抢占调度对访问共享数据是有代价的，对内核的设计也有影响。

与CPU调度功能有关的另一个部分是**分派程序(dispatcher)**。分派程序是一个模块，用来将CPU的控制交给由短期调度程序选择的进程。功能：

* 切换上下文
* 切换到用户模式
* 跳转到用户程序的合适位置，以重新启动程序

分派程序停止一个进程而启动另一个所要画的时间称为**分派延迟(dispatch latency)**。

## 5.2 调度准则

* CPU使用率
* 吞吐量
* 周转时间
* 等待时间
* 响应时间

## 5.3 调度算法

* **先到先服务调度**(first-come, first-served(**FCFS**) scheduling algorithm)

FCFS策略可以用FIFO队列来容易地实现，但是平均等待时间通常较长。(护航效果convoy effect)

FCFS调度算法是非抢占的。

* **最短作业优先调度算法**(shortest-job-first(**SJF**) scheduling algorithm)

SJF策略是最佳的，因为平均等待时间最小，但是真正困难是如何知道下一个CPU区间的长度。

SJF调度经常用于长期调度。SJF算法可能是抢占的或非抢占的，抢占SJF调度有时称为**最短剩余时间优先调度(shortest-remaining-time-first scheduling)**。

* **优先级调度算法**(priority scheduling algorithm)


SJF算法可作为通用优先级调度算法的一个特例。每个进程都有一个优先级与其关联，具有最高优先级的进程会分配到CPU，具有相同优先级的进程按FCFS顺序调度。

优先调度可以是抢占的或者非抢占的。优先级调度算法的一个主要问题是**无穷阻塞(indefinite blocking)**或**饥饿(starvation)**。低优先级进程无穷等待问题的解决之一是**老化(aging)**，逐渐增加在系统中等待很长时间的进程的优先级。

* **轮转法调度**(round-robin, RR)


轮转法调度算法是专门为分时系统设计的，类似于FCFS调度，但是增加了抢占以切换进程。定义一个较小时间单元，称为**时间片(time quantum, or time slice)**，将就绪队列作为循环队列，设置定时器在一个时间片之后中断。

RR算法的性能很大程度上依赖于时间片的大小。如果时间片很小，那么RR算法称为**处理器共享**，每个进程对于用户都有它自己的处理器。这种方法用在Control Data Corporation(CDC)的硬件上，可以用一组硬件和10组寄存器实现10个外设处理器。

根据经验，80%的CPU区间应该小于时间片。

* **多级队列调度**(multilevel queue scheduling algorithm)

多级队列调度算法将就绪队列分成多个独立队列，根据进程的属性，如内存大小、进程优先级、进程类型，一个进程被永久地分配到一个队列中。

每个队列有自己的调度算法，队列之间通常采用固定优先级抢占调度。

* **多级反馈队列调度**(multilevel feedback queue scheduling algorithm)

多级反馈队列调度算法允许进程在队列之间移动，主要实现是根据不同CPU区间的特点以区分进程。

## 5.4 多处理器调度

* **非对称多处理(asymmetric multiprocessing)**：让一个处理器处理所有的调度决定、I/O处理以及其他系统活动。
* **对称多处理(symmetric multiprocessing, SMP)**：每个处理器自我调度。

**处理器亲和力**是指SMP系统试图避免将进程从一个处理器移至另一个处理器，而是努力使一个进程在同一个处理器运行。

* **软亲和性(soft affinity)**：一个操作系统具有设法让一个进程保持在同一个处理器上运行的策略，但不能做任何保证。
* **硬亲和性(hard affinity)**：运行进程指定它不允许移至其他处理器上。

负载平衡通常有两种方法：**push migration**和**pull migration**。负载平衡常会抵消处理器亲和性的优点。

**对称多线程(SMT)**：提供多个逻辑处理器，也被称为**超线程技术(hyperthreading)**。

## 5.5 线程调度

* **进程竞争范围(process-contention scope, PCS)**：用户级线程
* **系统竞争范围(system-contention scope, SCS)**：内核线程

```c
#include <pthread.h>
#include <stdio.h>

#define NUM_THREADS 5

void* runner(void* param);

int main(int argv, char* args[]) {
    int scope;
    pthread_t tid[NUM_THREADS];
    pthread_attr_t attr;
    pthread_attr_init(&attr);
    if (pthread_attr_getscope(&attr, &scope) != 0) {
        fprintf(stderr, "Unable to get scheduling scope.\n");
    } else {
        if (scope == PTHREAD_SCOPE_PROCESS) {
            printf("PTHREAD_SCOPE_PROCESS\n");
        } else if (scope == PTHREAD_SCOPE_SYSTEM) {
            printf("PTHREAD_SCOPE_SYSTEM\n");
        } else {
            fprintf(stderr, "Illegel scope value.\n");
        }
        pthread_attr_setscope(&attr, PTHREAD_SCOPE_SYSTEM);
        for (int i = 0; i < NUM_THREADS; i++) {
            pthread_create(&tid[i], &attr, runner, NULL);
        }
        for (int i = 0; i < NUM_THREADS; i++) {
            pthread_join(tid[i], NULL);
        }
    }
}

void* runner(void* param) {
    printf("Hello, world\n");
    pthread_exit(0);
}
```

## 5.6 操作系统实例

* **Solaris调度**

Solaris采用基于优先级的线程调度，根据优先级不同，有4类调度：实时、系统、分时、交互。

|  调度类别  | 全局优先级 | 调度顺序 |        运行队列         |
| :--------: | :--------: | :------: | :---------------------: |
|    实时    |    最高    |    先    |    实时LWP的内核线程    |
|    系统    |    中级    |    中    |      内核服务线程       |
| 交互、分时 |    最低    |    后    | 交互和分时LWP的内核线程 |

进程默认的调度类型是分时，分时调度方法采用多级反馈队列，动态地调整优先级和赋予不同长度地时间片。Solaris 9引入了两种新的调度类型：**固定优先级(fixed priority)**、**公平共享(fair share)**。

* **Windows XP调度**

Windows XP采用基于优先级的、抢占调度算法来调度线程，调度程序使用32级优先级方案以确定线程执行的顺序。优先级分为两大类型：**可变类型(variable class)**包括1~15优先级的线程，**实时类型(real-time class)**包括16~31优先级的线程，优先级0的线程用于内存管理。

如果没有就绪线程，那么调度程序会执行一个称为**空闲线程(idle thread)**的特别线程。

* **Linux调度**

在2.5版本之前，Linux内核运行传统的Unix调度算法，不提供对SMP系统足够的支持，以及当系统任务数量增加时不能按比例调整。2.5版本之后，调度程序被分解，内核提供在固定时间内运行的调度算法。

Linux调度程序是抢占的、基于优先级的算法，具有两个独立的优先级范围：从0~99的**real-time**范围和从100~140的**nice**范围。与Solaris和Windows XP在内的其他许多系统的调度程序不同，Linux给较高的优先级分配较长的时间片，给较低的优先级分配较短的时间片。

## 5.7 算法评估

* **分析评估法(analytic evaluation)**：使用给定算法和系统负荷，产生一个公式或数字，以评估对于该负荷算法的性能。
* **确定模型法(deterministic modeling)**：采用特殊预先确定的负荷，计算在给定负荷下每个算法的性能。

# 第6章 进程同步

## 6.1 背景

多个进程并发访问和操作同一数据且执行结果与访问发生的特定顺序有关，称为**竞争条件(race condition)**。为了避免竞争条件，需要一定形式的**进程同步(process synchronization)**和**协调(coordination)**。

## 6.2 临界区问题

每个进程有一个代码段称为**临界区(critical section)**，在该区中进程可能改变共同变量、更新一个表、写一个文件等。当一个进程进入临界区，没有其他进程可被允许在临界区内执行，即没有两个进程可同时在临界区执行。

**临界区问题(critical-section problem)**是设计一个以便进程协作的协议。每个进程必须请求允许进入其临界区，实现请求的代码段称为**进入区(entry section)**，临界区之后有**退出区(exit section)**，其他代码为**剩余区(remainder section)**。

临界区问题的解答必须满足如下三项要求：

* **互斥(mutual exclusion)**：如果进程在其临界区内执行，那么其他进程都不能在其临界区内执行。
* **前进(progress)**：如果没有进程在其临界区内执行且有进程需进入临界区，那么只有那些不再剩余区内执行的进程可参加选择，以确定谁能下一个进入临界区，且这种选择不能无限推迟。
* **有限等待(bounded waiting)**：从一个进程做出进入临界区的请求，直到该请求允许为止，其他进程允许进入其临界区的次数有上限。

处理操作系统内的临界区问题：

* **抢占内核(preemptive kernel)**：允许处于内核模式的进程被抢占，适合实时编程，响应更快。
* **非抢占内核(non-preemptive kernel)**：不允许处于内核模式的进程被抢占，从根本上不会导致竞争条件。

## 6.3 Peterson算法

Peterson算法适用于两个进程在临界区与剩余区间交替执行。

```c
do {
    flag[i] = true;
    turn = j;
    while (flag[j] && turn == j);
    // 临界区
    flag[i] = false;
    // 剩余区
} while (true);
```

`i`是执行的进程，`j`是另一个进程，`ture`标识哪个进程可以进入其临界区，`turn`、`flag`是内存共享的。

## 6.4 硬件同步

任何临界区问题都需要一个简单工具——锁。

```c
do {
    // 请求锁
    // 临界区
    // 释放锁
    // 剩余区
} while (true);
```

许多现代计算机系统提供了特殊硬件指令以允许能原子地(不可中断地)检查和修改字地内容或交换两个字的内容(作出不可中断的指令)。

比如指令`TestAndSet()`的定义：

```c
bool TestAndSet(bool* target) {
    bool rv = *target;
    *target = true;
    return rv;
}
```

使用`TestAndSet()`的互斥实现：

```c
do {
    while (TestAndSet(&lock));
    // critical section
    lock = false;
    // remainder section
} while (true);
```

## 6.5 信号量

**信号量(semaphore)**用于解决`TestAndSet`、`Swap`使用复杂的问题。信号量S是个整数变量，除了初始化外，只能通过两个标准原子操作`wait()`和`signal()`来访问，这些操作被称为P(荷兰语`proberen`测试)和V(荷兰语`verhogen`增加)。

```c
wait(S) {
    while (S <= 0);
    S--;
}

signal(S) {
    S++;
}
```

操作系统区分**计数信号量**与**二进制信号量**，计数信号量的值域不受限制，而二进制信号量只能为0或1。通常称二进制信号量为**互斥锁**，因为可以提供互斥。

这里所定义的信号量的主要缺点是都要求**忙等待(busy waiting)**，这种类型的信号量也称为**自旋锁(spinlock)**。自旋锁的优点是，进程在等待锁时不进行上下文切换。

为了克服忙等待，可以修改信号量操作，使得进程不是忙等而是阻塞自己。这里信号量定义应该为如下结构体：

```c
typedef struct {
    int value;
    struct process* list;
} semaphore;
```

**死锁(deadlocked)**：两个或多个进程无限地等待一个事件，而该事件只能由这些等待进程之一来产生。

**无限期阻塞(indefinite blocking)**：**饥饿(starvation)**，即进程在信号量内无限期等待。

## 6.6 经典同步问题

* **有限缓冲问题**：通常用来说明同步原语地能力。
* **读者-写者问题**：写者对共享数据库有排他地访问。
* **哲学家进餐问题**：并发控制、同步问题，死锁与饥饿的典型例子。

## 6.7 管程

当信号量不正确地用来解决临界区问题时，会很容易地产生各种类型的错误。为了处理这些类型的错误，研究者提出高级的同步构造——**管程(monitor)**类型。

管程类型提供了一组由程序员定义的、在管程内互斥的操作。管程类型的表示包括一组变量的声明(这些变量的值定义了一个类型实例的状态)和对这些变量操作的子程序和函数的实现。管程类型的表示不能直接为各个进程所使用，在管程内定义的子程序只能访问位于管程内那些局部声明的变量和形式参数。类似地，管程的局部变量只能被局部子程序访问。

管程结构确保一次只有一个进程能在管程内活动。对于特定同步方案，需要定义一些额外的同步机制，这些可由**条件(condition)**结构来提供。

## 6.8 同步实例

* **Solaris同步**

为了控制访问临界区，Solaris提供了适应互斥、条件变量、信号量、读写锁和十字转门。

Java为线程同步提供一个类似于管程的并行机制，Java中的每一个对象都有一个单独的锁。当方法声明为`synchronized`时，调用方法要求拥有对象的锁。

```java
public class SimpleClass {
    public synchronized void safeMethod() {
        /* ... */
    }
}

SimpleClass sc = new SimpleClass();
```

调用`sc.safeMethod()`要求拥有对象实例`sc`的锁，如果锁被其他线程所有，则调用同步方法的线程阻塞，并被放入对象锁的进入集合中。

Java提供`wait()`和`notify()`方法，类似于管程的`wait()`、`signal()`的功能，在`java.util.concurrent`包中为信号量、条件变量、互斥锁还有其他并发机制提供API支持。

**适应互斥(adaptive mutex)**保护对每个临界数据项的访问。在多处理器系统中，适应互斥以自旋锁实现的标准信号量而开始，请求锁的线程可以选择自旋并等待锁可用，也可用阻塞进入睡眠直到锁释放被唤醒。在单处理器系统中，请求锁的线程总是睡眠而不是自旋，因为某一时刻只有一个线程可以运行。

Solaris使用适应互斥方法以保护那些为较短代码段所访问的数据，如果代码较长，那么自旋等待就极为低效了。

**读写锁**用于保护经常访问但通常是只读访问的数据，在这种情况下，读写锁比信号量更为有效。因为多个线程可以同时读数据，而信号量只允许顺序访问数据。读写锁实现代价要大，通常只用于很长的代码段。

Solaris使用**十字转门**以安排等待获取适应互斥和读写锁的线程链表。**十字转门(turnstile)**是一个队列结构，包含阻塞在锁上的线程。Solaris不是将每个同步对象与一个十字转门相关联，而是给每个内核线程一个十字转门。用于第一个线程阻塞于同步对象的十字转门成为对象本身的十字转门，以后阻塞于该锁上的线程会添加到该十字转门上。最终释放锁时，会从内核所维护的空闲十字转门中获得一个新的十字转门。

为了防止**优先级倒置**，十字转门根据**优先级继承协议**来组织。如果较低优先级的线程拥有一个较高优先级线程锁阻塞的锁，那么该低优先级线程会暂时继承较高优先级线程的级别。在释放线程之后，线程会返回到它原来的优先级。

* **Windows XP同步**

在单处理器中，Windows XP访问全局资源时，会暂时屏蔽所有可能访问该全局资源的中断处理程序的中断。在多处理器中，Windows XP采用自旋锁来保护对全局资源的访问。与Solaris一样，内核只使用自旋锁来保护较短代码段。由于效率原因，内核会确保拥有自旋锁的线程决不会被抢占。

对于内核外线程的同步，Windows XP提供了**调度对象(dispatcher object)**。采用调度对象，线程可根据多种不同机制，包括互斥、信号量、事件和定时器等来进行同步。

调度对象可以处于**触发状态(signal state)**或**非触发状态(non-signal state)**。触发状态表示对象可用且线程在获取它时不会阻塞，非触发状态表示对象不可用且当线程试图获取它时会阻塞。

* **Linux同步**

Linux内核提供自旋锁和信号量(还有着两种锁的读者-写者版本)，以进行内核加锁。Linux提供两个简单系统调用`preempt_disable`、`preempt_enable`用来禁止与允许内核抢占。

* **Pthread同步**

Pthread API为线程同步，提供互斥锁、条件变量、读写锁。

## 6.9 原子事务

数据库系统关注于数据的存储和提取及数据的一致性。

执行单个逻辑功能的一组指令或操作称为**事务(transaction)**。处理事务的主要问题是不管出现什么计算机系统的可能失败，都要保证事务的原子性。

从用户观点来看，事务只是一系列read操作和write操作，并以commit操作或abort操作终止。已成功完成执行的终止事务称为**提交(committed)**；否则，称为**撤销(aborted)**。被中止的事务所访问的数据状态必须回复到事务刚刚开始执行之前，即这个事务已经**回退(rolled back)**。

确保原子性的一种方法是在稳定存储上记录有关事务对其访问的数据所做各种修改的描述信息，实现着种形式记录最为常用的方法是**先记日志后操作**。

为了避免出错时搜索整个日志，引入了**检查点(checkpoint)**的概念。系统定期执行检查点，执行下列步骤：

1. 将当前驻留易失性存储的所有日志记录输出到稳定存储上。
2. 将当前驻留易失性存储的所有修改数据输出到稳定存储上。
3. 在稳定存储上输出一个日志记录`<checkpoint>`。

事务的并发执行必须相当于这些事务按任意顺序串行执行，这一属性称为**串行化(serializability)**。

* 串行化能力
* 加锁协议
* 基于时间戳的协议


# 第7章 死锁

## 7.1 系统模型

进程按下列顺序使用资源：申请，使用，释放。资源的申请与释放为系统调用。

当一组进程中的每一个进程都在等待一个事件，而这一事件只能由这一组进程的另一进程引起，那么这组进程就处于死锁状态。开发多线程应用可能因为竞争共享资源而容易产生死锁。

## 7.2 死锁特征

如果一个系统中下面4个条件同时满足，那么就会引起死锁。

* **互斥**：至少有一个资源必须处于非共享模式。
* **占有并等待**：一个进程必须占有至少一个资源，并等待另一资源，而该资源为其他进程所占有。
* **非抢占**：资源不能被抢占，即资源只能在进程完成任务后自动释放。
* **循环等待**：等待的资源被下一个进程占有。

很难识别并测试只在某种情况下发生的死锁。

根据资源分配图的定义，可以证明：如果分配图没有环，那么系统就没有进程死锁。如果分配图有环，那么可能存在死锁。如果每个资源类型只有一个实例，那么有环就意味死锁，如果有多个实例，有环也不意味死锁。

## 7.3 死锁处理方法

从原理上来说，有三种方法可处理死锁问题：

* 可使用协议以预防或避免死锁，确保系统不会进入死锁状态。
* 可允许系统进入死锁状态，然后检测它，并加以恢复。
* 可忽视这个问题，认为死锁不可能在系统内发生。

**死锁预防(deadlock prevention)**是一组方法，以确保至少一个必要条件不成立，这些方法通过限制如何申请资源的方法来预防死锁。

**死锁避免(deadlock avoidance)**要求操作系统事先得到有关进程申请资源和使用资源的额外信息，系统可确定对于申请进程是否应该等待。

## 7.4 死锁预防

通常不能通过否定互斥条件来预防死锁，因为有的资源本身就是非共享的。

 为了确保占有并等待条件不会在系统内出现，必须保证：当一个进程申请一个资源时，它不能占有其他资源。一种可以使用的协议时每个进程在执行前申请并获得所有资源，另一种协议允许进程在没有资源时才可申请资源。缺点：资源利用率可能比较低，可能发生饥饿。

如果一个进程占有资源并申请另一个不能立即分配的资源，那么其现已分配的资源都可被抢占。这个协议通常应用于状态可以保存和恢复的资源，比如CPU寄存器和内存。

对所有资源类型进行完全排序，且要求每个进程按递增顺序来申请资源。

## 7.5 死锁避免

死锁避免算法动态地检测资源分配状态以确保循环等待条件不可能成立。

* **资源分配图算法**：除了申请边和分配边之外，引入新类型的边，称为**需求边**。只有在将申请边变成分配边不会导致资源分配形成环时，才允许申请。
* **银行家算法**：当它不能满足所有客户的需要时，银行绝不会分配其现金。

## 7.6 死锁检测

如果一个系统既不采用死锁预防算法，也不采用死锁避免算法，那其应该提供：

* 一个用来检测系统状态从而确定是否出现了死锁的算法。
* 一个用来从死锁状态中恢复的算法。

当且仅当等待图中有一个环，系统中存在死锁。从图中检测环的算法需要$O(n^2)$复杂度。

## 7.7 死锁恢复

**进程终止**：

* 终止所有死锁进程
* 一次只终止一个进程直到取消死锁循环为止

**资源抢占**：通过抢占资源以取消死锁，逐步从进程中抢占资源给其他进程使用，直到死锁环被打破。

抢占需要处理三个问题：选择一个牺牲品、回滚、饥饿。

# 第8章 内存管理

## 8.1 背景

CPU内置寄存器通常可以在一个CPU时钟周期内完成访问，但完成内存访问可能需要多个CPU时钟周期。由于没有数据以便完成正在执行的指令，CPU通常需要**暂停(stall)**。解决方法是在CPU和内存之间，增加协调速度差异的内存缓存区，称为**高速缓存(cache)**。

为了确保每个进程都有独立的内存空间，需要确定进程可访问的合法地址的范围，并确保进程只访问其合法地址。通过基地址寄存器和界限地址寄存器，可以实现这种保护。**基地址寄存器(base register)**含有最小的合法物理内存地址，而**界限地址寄存器(limit register)**决定了范围的大小。只有操作系统可以通过特殊的特权指令来加载基地址寄存器和界限地址寄存器，特权指令只可在内核模式下执行。

地址绑定有以下几种情况：

* **编译时(compile time)**：如果编译时知道进程的驻留地址，就可以生成**绝对代码(absolute code)**。
* **加载时(load time)**：编译时不知道驻留地址，生成**可重定向代码(relocatable code)**。
* **执行时(execution time)**：如果进程在执行时可以从一个内存段移到另一个内存段，那么绑定必须延迟到执行才进行。采用这种方案需要特定的硬件，绝大多数通用计算机操作系统采用这种方法。

CPU所生成的地址通常称为**逻辑地址(logical address)**，而内存单元所看到的地址(即加载到内存地址寄存器的地址)通常称为**物理地址(physical address)**。逻辑地址又称为**虚拟地址(virtual address)**。

运行时从虚拟地址到物理地址的映射是由被称为**内存管理单元(memory-management unit, MMU)**的硬件设备来完成的，基地址寄存器在这里称为**重定位寄存器(relocation register)**。

**动态加载(dynamic loading)**：一个子程序只有在调用时才被加载，可重定向的链接程序加载所需要的子程序，并更新程序的地址表以反映着一变化。

**动态链接库(dynamically linked library)**的概念与动态加载相似，只不过不是将加载延迟到运行时，而是将链接延迟到运行时。动态链接可用于库更新，这种系统也称为**共享库**。

## 8.2 交换

进程可以暂时从内存中**交换(swap)**到**备份存储(backing store)**上，当需要再次执行时再调回到内存中。这种交换策略的变种被用在基于优先级的调度算法中，高优先级的进程可以换出低优先级的进程，这种交换有时候被称为**滚出(rool out)**和**滚入(roll in)**。

交换系统的上下文切换比较长，为了有效使用CPU，需要使每个进程的执行时间比交换时间长，交换时间的主要部分使转移时间。

早期PC缺乏高级硬件来实现高级内存的管理方法，但是通过使用修正过的交换可以运行多个大进程。

## 8.3 连续内存分配

内存通常分为两个区域：一个用于驻留操作系统，另一个用于用户进程。操作系统可以位于低内存段，也可以位于高内存，影响这一决定的主要因素使中断向量的位置。通常需要将多个进程同时放在内存中，采用**连续内存分配(contiguous memory allocation)**时，每个进程位于一个连续的内存区域。

最简单的内存分配方法之一就是将内存分为多个固定大小的**分区(partition)**，每个分区只能容纳一个进程，因此多道程序的程度会受分区数所限制。这种**多分区方法(multiple-partition method)**最初为IBM OS/360操作系统(MFT)所使用，时固定分区方案的推广(MVT)，主要用于批处理环境。

在**可变分区(variable-partition)**方案里，操作系统有一个表，用于记录哪些内存可用和哪些内存已被占用。一开始，所有内存都可用于用户进程，因此可用作为一大块可用内存，称为**孔(hole)**。

从一组可用孔中选择一个空闲孔的最为常用方法有**首次适应(first-fit)**、**最佳适应(best-fit)**、**最差适应(worst-fit)**。

* **首次适应**：分配第一个足够大的孔。
* **最佳适应**：分配最小的足够大的孔。
* **最差适应**：分配最大的孔。

首次适应和最佳适应在执行时间和利用空间上都比最差适应要好，首次适应比最佳适应速度要快。但是，首次适应方法和最佳适应方法算法都有**外部碎片问题(external fragmentation)**。

内存碎片可以是内部的，也可以是外部的。一个解决外部碎片问腿的方法是**紧缩(compaction)**，紧缩的目的是移动内存内容，以便所有空闲空间合并成一整块。另一个解决方法是允许物理地址空间是非连续的，这样只要有物理内存就可以为进程分配了，这种方案有两种互补实现技术：分页和分段。

## 8.4 分页

**分页(paging)**内存管理方案允许进程的物理地址空间可以是非连续的。实现分页的基本方法涉及将物理内存分为固定大小的块，称为**帧(frame)**，将逻辑内存也分为同样大小的块，称为**页(page)**。

由CPU生成的每个地址分为两个部分：**页号(p)**、**页偏移(d)**。页号作为**页表**中的索引，页表包含每页所在物理内存的基地址，这些基地址和页偏移的组合就形成了物理地址。

页大小和帧大小是由硬件来决定的，通常为2的幂，根据计算机结构的不同，其每页大小从512B~16M不等。分页也是一种动态重定向，每个逻辑地址由分页硬件绑定为一定的物理地址。采用分页技术不会产生外部碎片，每个帧都可以分配给需要它的进程，不过分页有内部碎片。

每个页表的条目通常是4B，如果帧尾4K，那么具有4B条目的系统可以访问16T的物理内存。

分页的一个重要特点是用户视角的内存和实际的物理内存的分离。

在**帧表(frame table)**中，每个条目对应一个帧，以表示该帧是空闲还是已占用。

每个操作系统都有自己的方法来保存页表，绝大多数都为每个进程分配一个页表，页表的指针与其他寄存器的值一起存入进程控制块中。页表的硬件实现有很多种方法，最为简单的一种方法是将页表作为一组专用寄存器来实现。如果页表非常大，那么需要将页表存在内存中，并将**页表基寄存器(page-table base register, PTBR)**指向页表。

**转换表缓冲区(translation look-aside buffer, TLB)**解决访问速度慢问题，TLB条目由键和值组成。如果页码不再TLB中，就称为**TLB失效**，那么就需要访问页表。有的TLB在每个TLB条目中保存**地址空间标识符(address-space identifier, ASID)**，可以用来唯一地标识进程，并为进程提供地址空间保护。

可以用一个位来定义一个页是可读写还是只读的，还有一个位通常与页表中的每一条目相关联——**有效-无效位**。有些系统提供硬件如**页表长度寄存器(page-table length register, PTLR)**来表示页表的大小，该寄存器的值可用于检查每个逻辑地址以验证其是否位于进程的有效范围内。

分页的优点之一在于可以共享公共代码，这种考虑对分时环境特别重要，**可重入代码(reentrant code, 纯代码)**可以共享，可重入代码是不能自我修改的代码，在执行期间不会改变。

## 8.5 页表结构

我们不可能在内存中连续地分配4MB物理地址空间来存储页表本身，需要将页表划分为更小部分。

* **层次页表**：将页表再分页，由于地址转换由外向内，这种方案也称为**向前映射页表(forward-mapped page table)**。但是对于64位体系结构，层次页表通常并不适合。
* **哈希页表(hashed page table)**：以虚拟页码作为哈希值，每一条目都包含一个链表的元素，元素有3个域：虚拟页码、所映射的帧号、指向链表下一个元素的指针。
* **群集页表(clustered page table)**：类似哈希页表，比较适合64位地址空间，不过群集页表每一条目包含多页，对于稀疏地址空间特别有用。
* **反向页表(inverted page table)**：反向页表对于每个真正的内存页或帧才有一个条目，每个条目包含保存再真正内存位置的页的虚拟地址以及拥有该页的进程的信息。因此，整个系统只有一个页表。

## 8.6 分段

**分段(segmentation)**是支持用户视角的内存管理方案，用户认为程序是由方法、过程、函数组成。逻辑地址空间是由一组段组成的，每个段都有名字和长度，地址指定了段名词和段内偏移。因此，用户通过两个量来指定地址：段名称、偏移，而分页只需要指定偏移。

一个C编译器可能会创建如下的段：

* 代码
* 全局变量
* 堆，内存从堆上分配
* 每个线程采用的栈
* 标准的C库函数

**段表(segment table)**可以将二维的用户定义地址映射为一维物理地址，段表每个条目都有段基地址和段界限，段基地址包含该段在内存中的开始物理地址，而段界限指定该段的长度。

## 8.7 实例：Intel Pentium

在Pentium系统中，CPU产生逻辑地址，它被赋给分段单元。分段单元为每个逻辑地址生成线性地址，然后线性地址交给分页单元，接下来生成内存中的物理地址。分段单元和分页单元相当于内存管理单元(MMU)。

* **Pentium分段**

Pentium结构允许一个段的大小最多可达4GB，每个进程最多的段数量为16K个。

进程的逻辑地址空间被分为两部分：第一部分最多由8K个段组成，这部分为私有；第二部分最多由8K个段组成，这部分为所有进程所共享。第一部分的信息保存在**本地描述符表(local descriptor table, LDT)**中，而第二部分的信息保存在**全局描述符表(global descriptor table, GDT)**中。LDT和GDT的每个条目为8B，包含一个段的详细信息，如基位置和段界限。

逻辑地址是一对`(selector, offset)`：**选择器(selector)**是一个16位的数，13位表示段号，1位表示段在GDT还是LDT，2位表示保护信息；**偏移(offset)**是一个32位的数，用来表示字节或字在段内的位置。

机器有6个段寄存器，允许一个进程可以同时访问6个段，还有6个8B的微程序寄存器，用来保存相应的来自于LDT或GDT的描述符。

Pentium的线性地址为32位长，段寄存器指向LDT或GDT中的适当条目，段的基地址和界限信息用来产生线性地址。

* **Pentium分页**

Pentium体系结构允许页的大小为4KB或4MB，对4KB的页，Pentium采用二级分页方案。页码的高10位引用最外层页表的条目，它被称为**页目录(page directory)**(CR3寄存器指向当前进程的页目录)。页目录条目指向由线性地址中最内层的10位内容索引的内部页表。最低12位是偏移。

* **Pentium系统上的Linux**

Linux并不依赖段，并最低程度地使用它，在Pentium中，Linux仅用6个段：内核代码段、内核数据段、用户代码段、用户数据段、任务状态段(TSS)、默认的LDT段。尽管Pentium采用二级分页模式，Linux采用适合32位和64位体系结构的三级分页方案。

# 第9章 虚拟内存

## 9.1 背景

在许多情况下，并不需要将整个程序放到内存中：

* 程序的处理异常错误条件的代码几乎不执行。
* 数组、链表和表通常分配了比实际所需要的更多的内存。
* 程序的某些选项或功能可能很少使用。

**虚拟内存(virtual memory)**将用户逻辑内存与物理内存分开，进程的虚拟地址空间就是进程如何在内存中存放的逻辑(或虚拟)视图。包含空白的虚拟地址空间称为稀地址空间，随程序的执行，栈或堆段的生长或需要载入动态链接库(或共享对象)时，这些空白可以填充。

## 9.2 按需调页

**按需调页(demand paging)**：在需要时才调入相应的页，常为虚拟内存系统所采用。**懒惰交换(lazy swapper)**只有在需要页时，才将它调入内存。

当进程试图访问尚未调入到内存的页时，对标记为无效的访问会产生**页错误陷阱(page-fault trap)**，处理如下：

1. 检查进程的内部页表(通常与PCB一起保存)，以确定该引用是合法还是非法的地址访问。
2. 如果引用非法，那么终止进程；如果引用有效但是尚未调入页面，那么调入。
3. 找到一个空闲帧。
4. 调度一个磁盘操作，将所需要的页调入刚分配的帧中。
5. 修改进程的内部表和页表，以表示该页已在内存中。
6. 重新开始因陷阱而中断的指令。

**纯粹按需调页(pure demand paging)**：只有在需要时才将页调入内存。

按需调页内存的**有效访问时间(effective access time)**为$(1-p) \times ma + p \times 页错误时间$，其中p页错误的概率($0 \le p \le 1$)，ma为内存访问时间(10~200ns)。

## 9.3 写时复制

**写时复制(copy-on-write)**允许父进程与子进程开始时共享同一页面，这些页面标记为写时复制页，即如果任何一个进程需要对页进行写操作，那么就创建一个共享页的副本。

许多操作系统提供了系统调用fork()的变种——vfork()，虚拟内存fork。vfork()会将父进程挂起，子进程使用父进程的地址空间，如果子进程修改父进程地址空间的任何页，那么这些修改过的页在父进程重启时是可见的。vfork主要用于在子进程被创建之后立即调用exec()的情况。

## 9.4 页面置换

**页置换(page replacement)**：

1. 查找所需页在磁盘上的位置。
2. 查找一个空闲帧。
   * 如果有空闲帧，那么就使用它。
   * 如果没有空闲帧，那么久使用页置换算法以选择一个**牺牲帧(victim frame)**。
   * 将牺牲帧的内容写到磁盘中，改变页表和帧表。
3. 将所需页读入空闲帧，改变页表和帧表。
4. 重启用户进程。

可以通过使用**修改位(modify bit)**或**脏位(dirty bit)**以降低额外开销。按需调页需要实现两个算法：**帧分配算法(frame-allocation algorithm)**、**页置换算法(page-replacement algorithm)**。

* **FIFO页置换**

FIFO当必须置换一页时，将选择最旧的页。不需要记录调入页的确切时间，可以创建一个FIFO队列来管理内存中所有的页。

**Belady异常(Belady's anomaly)**：对有的页置换算法，页错误率可能会随着所分配的帧数的增加而增加，而原期望为进程增加内存会改善其性能。

* **最优置换**

**最优页置换(optimal page-replacement algorithm)**是所有算法中产生页错误率最低的，且绝没有Belady异常的问题，被称为OPT或MIN。它会置换最长时间不会使用的页。

* **LRU页置换**

**最近最少使用算法(least-recently-used algorithm)**置换最近最长时间没有使用的页，使用离过去最近作为不远将来的近似。为页帧确定一个排序序列的可行实现：计数器、栈。

最优置换和LRU置换都属于同一类算法，称为**栈算法(stack algorithm)**，都没有Belady异常。

* **近似LRU页置换**

附加引用位算法在规定时间间隔里记录引用位，操作系统把每个页的引用位转移到其8位字节的高位，而将其他位右移一位，并抛弃最低位。历史位的数量可以修改，甚至可以只有引用位本身，这种情况称为**第二次机会页置换算法(second-chance page-replacement algorithm)**。

二次机会置换的基本算法是FIFO置换算法，可以采用循环队列。如果所有位均已设置，那么二次机会置换久变成了FIFO置换。

增强型二次机会算法通过将引用位和修改位作为一有序对来考虑，有四种可能类型：最近没有使用且没有修改、最近没有使用但修改过、最近使用过但没有修改、最近使用过且修改过。这里给修改过的页更高的级别，从而降低所需I/O数量。

* **基于计数的页置换**

可以给每个页保留一个用于记录其引用次数的计数器，有：**最不经常使用页置换算法(least frequently used(LFU) page-replacement algorithm)**、**最常使用页置换算法(most frequently used(MFU page-replacement algorithm))**。需要定期地将次数寄存器右移一位，以形成指数衰减的平均次数。

* **页缓冲算法**

系统保留一个空闲帧缓冲池，用于存储牺牲帧和将要换入的页。页缓冲算法与FIFO置换算法一起用于VAX/VMS系统中。

* **应用程序与页置换**

操作系统允许特殊程序将磁盘作为逻辑块数据使用，而不需要通过文件系统的数据结构，这种数组有时称为**生磁盘(raw disk)**。

## 9.5 帧分配

帧分配策略受到多方面的限制，所分配的帧不能超过可用帧的数量(除非有页共享)，页必须分配至少最少数量的帧。

**平均分配(equal allocation)**：在n个进程之间分配m个帧的最容易的方法是给每个一个平均值，即m/n帧。

**比例分配(proportional allocation)**：根据进程大小，而将可用内存分配给每个进程。

页置换算法分为两大类：**全局置换(global replacement)**、**局部置换(local replacement)**。全局置换允许一个进程从所有帧集合中选择一个置换帧，而不管该帧是否已分配给其他进程。局部置换要求每个进程仅从其自己的分配帧中进行选择。因此，存在分配方案允许高优先级进程从低优先级进程中选择帧以便置换。

## 9.6 系统颠簸

频繁的页调度行为称为**颠簸(thrashing)**，如果一个进程在换页上用的时间要多于执行时间，那么这个进程就在颠簸。

通过**局部置换算法**(或**优先置换算法**)能限制系统颠簸，采用局部置换，如果一个进程开始颠簸，那么它不能从其他进程拿到帧，且不能使后者也颠簸。为了防止颠簸，必须提供进程所需的足够多的帧。工作集合策略是研究实际正在使用多少帧的策略，这种方法定义了进程执行的**局部模型(locality model)**。

**工作集合模型(working-set model)**是基于局部性假设的，该模型使用参数$\Delta$定义**工作集合窗口(working-set window)**，其思想是检查最近$\Delta$个页的引用，这最近$\Delta$个引用的页集合称为**工作集合(working set)**。

工作集合模型能用于预先调页，但是用于控制颠簸不太灵活，一种更为直接的方法是采用**页错误频率(page-fault frequency, PFF)**策略。

## 9.7 内存映射文件

文件的**内存映射(memory mapping)**：允许虚拟内存技术将文件I/O作为普通内存访问。有的操作系统只能通过特定的系统调用提供内存映射，而通过标准的系统调用处理所有其他文件I/O；而有的系统不管文件是否说明为内存映射，都选择对文件进行内存映射。

多个进程可以允许将同一文件映射到各自的虚拟内存中，以允许数据共享。

UNIX和Linux系统使用`mmap()`系统调用进行内存映射，使用POSIX兼容的`shmget()`和`shmat()`系统调用进行内存共享。但对于Windows NT，共享内存是通过内存映射文件来实现的。

`CreateFileMapping()`函数的调用创建一个称为共享对象(Shared Object)的**命名共享内存对象(named shared-memory object)**，消费者进程通过创建一个到相同的命名对象的映射，从而使用这个共享内存段进行通信。

## 9.8 内核内存的分配

内核内存的分配通常是从空闲内存池中获取，而不是从满足普通用户模式进程的内存链表中获取。原因有二：

* 内核需要为不同大小的数据结构分配内存，其中有的不到一页，内核必须谨慎使用内存。
* 用户进程所分配的页不必要在连续的物理内存中。

**Buddy系统**从物理上连续的大小固定的段上进行分配，内存按2的幂的大小来进行分配。Buddy系统的优点是可通过合并而快速地形成更大的段，缺点是由于调整到下一个2的幂容易产生碎片。

**slab系统**是由一个或多个物理上连续的页组成的，高速缓存(cache)含有一个或多个slab，每个cache含有内核数据结构的对象实例。Linux的slab有三个状态：满的、空的、部分。

## 9.9 其他考虑

纯按需调页系统一个显著特征是当一个进程开始时会出现大量页错误，**预调页(prepaging)**试图阻止这种大量的初始调页。

**TLB命中率(hit ratio)**是指通过TLB而不是页表所进行的虚拟地址转换的百分比，与命中率相关的另一类似测量尺度是**TLB范围(TLB reach)**，是指通过TLB可访问的内存量。增加TLB范围的另一个方法是增加页的大小或提供多种页大小。

## 9.10 操作系统实例

* **Windows XP**

Windows XP采用请求页面调度加上**簇(clustering)**来实现虚拟内存，簇在处理页错误时，不但调入出错的页面，而且还调入出错页周围的页。进程在创建时会被分配工作集合的最小值和最大值，**工作集合最小值(working-set minimum)**是进度在内存中时所保证有的页数量的最小值。

* **Solaris**

对于Solaris，当一个线程产生一次页错误时，内核会从其所维护的空闲链表中为页错误线程分配一个页。空闲链表有个参数叫lotsfree，用于表示开始调页的阈值，通常为物理内存大小的1/64。如果空闲页数少于lotsfree，就启动称为**换页(pageout)**的进程，换页进程采用类似二次机会算法的算法(也称为**双指针轮转算法(two-handed-clock algorithm)**)，其不同之处在于使用两个指针扫描页面。

# 第10章 文件系统接口

## 10.1 文件概念

文件有一定的属性：名称、标识符、类型、位置、大小、保护、时间日期和用户标识。

文件属于**抽象数据类型**，操作系统有6个基本文件操作：创建文件、写文件、读文件、在文件内重定向、删除文件、截断文件。

操作系统维护一个包含所有打开文件的信息表(**打开文件表**，open-file table)，当需要一个文件操作时，可通过该表的一个索引指定文件，而不需要搜索。操作系统采用两级内部表，单个进程的表和整个系统的表。

UNIX系统采用**幻数(magic number)**(保存在文件的开始部分)大致表明文件类型。Macintosh要求每个文件包括两个部分：**资源叉(source fork)**、**数据叉(data fork)**。

## 10.2 访问方法

* 顺序访问：文件信息按顺序，一个记录接着一个记录地加以处理。
* 直接访问：文件由固定长度的逻辑记录组成。
* 索引访问：首先搜索索引，再根据指针直接访问文件。

## 10.3 目录结构

目录可看做符号表，它能将文件名称转换成目录条目。目录相关的操作有：搜索文件、创建文件、删除文件、遍历目录、重命名文件、跟踪文件系统。

* **单层结构目录**：所有文件都包含在同一个目录中。
* **双层结构目录**：每个用户都有自己的**用户文件目录**(user file directory，UFD)，当一个用户作业开始执行或用户注册时，就搜索系统的**主文件目录**(master file directory，MFD)。
* **树状结构目录**：目录(或子目录)包含一组文件和子目录。
* **无环图目录**：无环图(acyclic graph)允许目录含有共享子目录和文件，同一个文件或子目录可出现在两个不同目录下。**软链接**删除文件会产生悬空引用，**硬链接**保留文件直到不存在引用。
* **通用图目录**：目录中允许有环存在。

## 10.4 文件系统安装

文件系统在被系统上的进程使用之前必须**安装(mount)**。操作系统需要知道设备名称和文件系统的安装位置，称为**安装点(mount point)**，通常安装点为空目录。

## 10.5 文件共享

在UNIX系统中，一个文件的拥有者可对文件执行所有操作，文件组的成员只能执行这些操作的子集，而所有其他用户可能只能执行另一操作子集。

**一致性语义(consistency semantics)**是评估文件系统对文件共享支持的一个重要准则，这是描述多用户同时访问共享文件时的语义。

## 10.6 保护

文件保护的需要是允许访问的直接结果，保护机制需要提供控制访问。

实现基于身份访问的最为普通的方法是为每个文件和目录增加一个**访问控制列表(access-control list，ACL)**，以给定每个用户名及其所允许的访问类型。通常有三个用户类型：**拥有者**、**组**、**其他**。

保护问题的另一解决方案是为每个文件或目录加上密码。

# 第11章 文件系统实现

## 11.1 文件系统结构

硬盘的特点：

* 可以原地重写。
* 可以直接访问磁盘上的任意一块信息。

为了改善I/O效率，内存与磁盘之间的I/O转移是以块为单位而不是以字节为单位来进行的，每块为一个或多个扇区。

文件系统本身通常由许多不同的层组成：应用程序、逻辑文件系统、文件组织系统、基本文件系统、I/O控制、设备。

**I/O控制**为最底层，由设备驱动程序和中断处理程序组成，实现内存与磁盘之间的信息传输。**基本文件系统**只需要向合适的设备驱动程序发送一般命令就可对磁盘上的物理块进行读写。**文件组织模块**知道文件及其逻辑块和物理块。**逻辑文件系统**管理元数据，元数据包括文件系统的所有结构数据，而不包括实际数据。

## 11.2 文件系统实现

* 每个卷的**引导控制块(boot control block)**包括系统从该卷引导操作系统所需要的信息。UFS称之为**引导块(boot block)**，NTFS称之为**分区引导扇区(partition boot sector)**。
* 每个卷的**卷控制块(volume control block)**包括卷(或分区)的详细信息，如分区的块数、块的大小、空闲块的数量和指针、空闲FCB的数量和指针等。UFS称之为**超级块(superblock)**，NTFS将其存储在**主控文件表(master file table)**中。

对于访问打开文件表的索引，UNIX称之为**文件描述符(file descriptor)**，Windows称之为**文件句柄(file handle)**。

分区可以是生的，即没有文件系统；或者是熟的，即含有文件系统。**根分区(root partition)**包括操作系统内核或其他系统文件，在引导时装入内存。

**虚拟文件系统(VFS)层**的两个目的：

* VFS层通过定义一个清晰的VFS接口，以将文件系统的通用操作和具体实现分开。
* VFS提供了在网络上唯一标识一个文件的机制，VFS基于称为vnode的文件标识结构。

Linux VFS定义的4中主要对象类型是：

* **索引节点对象(inode object)**：表示一个单独的文件。
* **文件对象(file object)**：表示一个打开的文件。
* **超级块对象(superblock object)**：表示整个文件系统。
* **目录条目对象(dentry object)**：表示一个单独的目录条目。

## 11.3 目录实现

* **线性列表**：使用存储文件名和数据块指针的线性列表，简单但运行较为费时。
* **哈希表**：需要一些预备措施来避免**冲突(collision)**。

## 11.4 分配方法

* **连续分配(contiguous allocation)**：要求每个文件在磁盘上占有一组连续的块。
* **链接分配(linked allocation)**：每个文件是磁盘块的链表，磁盘块分布在磁盘的任何地方。一个采用链接分配方法的变种是**文件分配表(FAT)**的使用，与链表相似。
* **索引分配(indexed allocation)**：通过把所有指针放在一起，即通过索引块解决直接访问问题。索引块有链接方案、多层方案、组合方案。

## 11.5 空闲空间管理

为了记录空闲磁盘空间，系统需要维护一个**空闲空间链表(free-space list)**。

* **位图**：通常，空闲空间表的实现为**位图(bit map)**或**位向量(bit vector)**，每块用一位来表示。在使用位图的系统上找到第一个空块来分配磁盘空间的一种技术是按顺序检查位图的每个字以检查其是否为0，依赖于硬件特性。
* **链表**：空闲空间管理另一种方法是将所有空闲磁盘块用链表连接起来，并将指向第一空闲块的指针保存在磁盘的特殊位置，同时缓存在内存中。分配空闲块时，只需要分配第一块。
* **组**：对空闲链表的一个改进是将n个空闲块的地址存在第一个空闲块中，可以很快找到大量空闲块。
* **计数**：可以记录第一块空闲块的地址和紧跟第一块的连续的空闲块的数量n。

## 11.6 效率与性能

磁盘空间的有效使用主要取决于所使用的磁盘分配和目录管理算法。

有的系统由一块独立内存用作**缓冲缓存**，位于其中的块假设马上需要使用。其他系统采用**页面缓存(page cache)**来缓存文件数据。页面缓存使用虚拟内存技术，将文件数据作为页面而不是面向文件系统的块来缓存。因为虚拟内存不能直接与缓冲缓存进行交流，所以缓冲缓存内的文件必须复制到页面缓存中，这种情况称为**双重缓存(double caching)**，需要两次缓存文件数据。如果提供了统一缓冲缓存，内存映射与系统调用都使用统一的页面缓存，就可以避免双重缓存。

## 11.7 恢复

**一致性检查程序(consistency checker)**会将目录结构数据与磁盘数据块相比较，并试图纠正所发现的不一致。

* **完全备份(full backup)**：将所有数据备份到介质上。
* **增量备份(incremental backup)**：将完全备份之后第n天以来改变过的数据备份到介质上。

## 11.8 基于日志结构的文件系统

**基于日志的面向事务文件系统(log-based transaction-oriented or journaling file system)**可以采用基于日志的恢复技术，以更新文件系统元数据。执行一个特殊任务的一组操作称为**事务(transaction)**。

## 11.9 NFS

NFS规范区分两种服务：一是由安装机制所提供的服务，二是真正远程文件访问服务。相应地，有两种协议用于这两个服务：一种是安装协议，另一种是远程文件访问协议，即**NFS协议**。协议是用RPC来表示的。

**安装协议(mount protocol)**在客户机和服务器之间建立初始逻辑连接，安装操作包括要安装的远程目录的名称和存储它的服务器的名称。服务器维护一个**输出列表(export list)**，它列出哪些本地文件系统允许输出以便安装。

NFS协议提供了一组RPC以供远程文件操作：

* 搜索目录内的文件
* 读一组目录条目
* 操作链接和目录
* 访问文件属性
* 读和写文件

NFS服务器的一个显著特点是无状态，服务器并不维护客户机的每一步访问信息。NFS中的**路径名转换(path-name translation)**包括把路径名解析成独立的目录条目或组成部分，并为每个组成名称和目录虚拟节点对执行独立的NFS lookup调用。

## 11.10 实例：WAFL文件系统

**WAFL(write-anywhere file layout)**是针对随机写优化的强大且简洁的文件系统，是一个分布式文件系统。

# 第12章 大容量存储器的结构

## 12.1 大容量存储器结构简介

**传输速率(transfer rate)**是在驱动器和计算机之间的数据传输速率。**定位时间(positioning time)**，有时称为**随机访问时间(random access time)**，由**寻道时间(seek time)**(移动磁臂到索要的柱面所需时间)和**旋转等待时间(rotational latency)**(等待所要的扇区旋转到磁臂下所需时间)组成。

**磁头碰撞(head crash)**是指磁头损坏磁盘表面，磁头碰撞不能修复，此时整个磁盘必须替换。

**软盘(floppy disk)**是较为便宜的可移动磁盘，它有一个软塑料盒以保存柔软的磁盘片。

磁盘驱动器通过一组称为**I/O总线(I/O bus)**的线与计算机相连，有多种可用总线，包括EIDE、ATA、串行ATA、USB、FC、SCSI。

## 12.2 磁盘结构

现代磁盘驱动器可用看做一个一维的**逻辑块**的数组，逻辑块是最小的传输单位，通常为512B。

通过映射，至少从理论上能将逻辑块号转换为由磁盘内的柱面号、柱面内的磁道号、磁道内的扇区号所组成的老式磁盘地址。实际上，执行这种转换并不容易，理由有二：

1. 绝大多数磁盘都有一些缺陷扇区。
2. 对于某些磁盘，每个磁道的扇区数并不是常量。

对于使用**常量线性速度(constant linear velocity, CLV)**的介质，每个磁道的位密度是均匀的，磁道离磁盘中心越远，能容纳更多的扇区。

如果磁盘转动速度不变，那么从内磁道到外磁道的位密度要不断降低以保持数据率的不变。这种方法被用在硬盘中，称为**恒定角速度(constant angular velocity, CAV)**。

## 12.3 磁盘附属

计算机访问磁盘存储有两种方式：

* 通过I/O端口，或**主机附属存储(host-attached storage)**。
* 通过分布式文件系统的远程主机，称为**网络附属存储(network-attached storage)**。

## 12.4 磁盘调度

* **FCFS调度**：先来先服务算法，最简单的磁盘调度形式，算法本身比较公平，但通常无法提高最快的服务。
* **SSTF调度**：最短寻道时间优先算法(shortest-seek-time-first, SSTF)，先处理靠近当前磁盘位置的请求。SSTF基本是一种最短作业优先(SJF)调度，可能导致一些请求得不到服务。
* **SCAN调度**：磁臂从磁盘的一端向另一端移动，当到达另一端时改变磁头移动方向，来回扫描。被称为**电梯算法(elevator algorithm)**。
* **C-SCAN调度**：circular SCAN，SCAN调度的变种，主要提高一个更为均匀的等待时间。磁头返回到磁盘开始时不处理请求。
* **LOOK调度**：磁头只移动到一个方向上最远的请求为止，其变种为**C-LOOK调度**。

## 12.5 磁盘管理

在磁盘能存储数据之前，它必须分成扇区以便磁盘控制器能读和写，这个过程称为**低级格式化**(或**物理格式化**)。每个扇区的数据结构通常由头、数据区域(通常512B)和尾部组成。头尾保护了一些磁盘控制器所使用的信息，如扇区号码和**纠错代码(error-correcting code, ECC)**。
